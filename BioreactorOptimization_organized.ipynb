{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c39187f-b352-4378-8ee9-8890c2e16306",
   "metadata": {},
   "source": [
    "# Bioreactor Optimization Using Machine Learning\n",
    "### CHE 883 Final Project \n",
    "##### Sam Schulte and Lauren Murray\n",
    "##### April 25, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ad0418-a64b-41f2-991f-017555f28caf",
   "metadata": {},
   "source": [
    "The purpose of this project is to recreate the work of the following paper: \n",
    "\n",
    "[Y. Ma, D. A. Noreña-Caro, A. J. Adams, T. B. Brentzel, J. A. Romagnoli, and M. G. Benton, “Machine-learning-based simulation and fed-batch control of cyanobacterial-phycocyanin production in Plectonema by artificial neural network and deep reinforcement learning,” Computers & Chemical Engineering, vol. 142, p. 107016, Jul. 2020, doi: 10.1016/j.compchemeng.2020.107016.](https://www.sciencedirect.com/science/article/abs/pii/S0098135420300545)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c15c77-8630-4ef9-bee0-0a4d97cc705d",
   "metadata": {},
   "source": [
    "--- \n",
    "### Table of Contents\n",
    "* [Introduction](#Introduction)\n",
    "* [Importing Libraries](#Importing-Libraries)\n",
    "* [Importing Data](#Importing-Data)\n",
    "* [Data Preprocessing](#Data-Preprocessing)\n",
    "    * [REGEM Imputation](#REGEM-Imputation)\n",
    "    * [Polynomial Fitting](#Polynomial-Fitting)\n",
    "    * Formatting Training and Validation Data for ANN\n",
    "    * Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082e14b5-53e0-4a6b-9a77-6b714b8577f9",
   "metadata": {},
   "source": [
    "---\n",
    "### Introduction\n",
    "\n",
    "This paper aimed to generate a machine learning (ML)-based strategy for optimizing the production of cyanobacterial-phycocyanin (C-PC), a valuable product produced by *Plectonoma* cyanobacteria. A deep reinforcement learning (DRL) algorithm, which are highly proficient with control tasks, was implemented to determine the optimal amount and timing of nitrate to add in a fed-batch culture to optimize C-PC production. In DRL, an agent interacts with an environment to maximize a reward in order to determine the best action to take. \n",
    "\n",
    "One challenge in implementing DRL is the need for many iterations to reach convergence, requiring a simulated reaction environment to model actions. Such a simulated environment can be generated relatively easily for systems in which the details of the reaction mechanism are known. However, for C-PC production in *Plectonoma*, no mechanistic understanding exits. Thus, the authors used a data-driven approach, training an artificial neural network (ANN) to simulate the environment. \n",
    "\n",
    "Here, we use the same training data as used in the paper. We pre-process the data, train an ANN to simulate the reaction environment, and implement a DRL algorithm to maximize C-PC production by determining optimal nitrate addition using the ANN environment. \n",
    "\n",
    "<span style=\"color:red\">**(add something about how successful we were in reproducing the code)**</span>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9890e10e-1367-426f-83fe-c21007b014b2",
   "metadata": {},
   "source": [
    "[Back to top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970d5d17-c7ba-43f7-84ba-301c55b2938e",
   "metadata": {},
   "source": [
    "---\n",
    "### Importing Libraries\n",
    "Necessary packages for processing data and implementing ML models are imported below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683cfe41-b115-4a69-8a99-ba2ec8d3c7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from fancyimpute import IterativeImputer\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Model\n",
    "import threading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8238db35-39e3-4dac-9eee-0b5a88d23a2e",
   "metadata": {},
   "source": [
    "[Back to top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf4e032-d782-46a3-8ac6-86dd10319f52",
   "metadata": {},
   "source": [
    "---\n",
    "### Importing Data\n",
    "\n",
    "**Source of Data:**  \n",
    "Data was downloaded from the Supplementary Materials of the paper. The raw data is contained in \"fitted data.xlsx\". We reformatted this data in a new excel sheet (\"cleaned_bioreactor_data.xlsx\") for ease of importing with pandas. This new excel sheet is available on this GitHub page. \n",
    "\n",
    "**Experimental Conditions:**  \n",
    "The authors of the papers performed four experiments to use for model training and validation. These experiments were performed under the same conditions except for (1) initial nitrate concentration and (2) time:\n",
    "| Experiment | Initial Nitrate Concentration (mg/L) | Time (Days) |\n",
    "|------------|--------------------------------------|-------------|\n",
    "| 1          | 300                                  | 17          |\n",
    "| 2          | 600                                  | 17          |\n",
    "| 3          | 900                                  | 17          |\n",
    "| 4          | 1200                                 | 55          |  \n",
    "\n",
    "**Data Naming Conventions:**  \n",
    "In the following code, variables containing experimental data are named based on their initial nitrate concentration (e.g., data300 contains data from Experiment 1, with an intial nitrate concentraiton of 300 mg/L)\n",
    "\n",
    "**Training and Validation Split:**  \n",
    "Datasets with initial nitrate concentrations of 300, 900, and 1200 mg/L were used for training the ANN, while the fourth dataset (600 mg/L) was used for ANN validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec0cdb5-02aa-45d8-ade4-a5cc1ff1f84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data300 = pd.read_excel(\"cleaned_bioreactor_data.xlsx\", engine=\"openpyxl\", sheet_name=\"300\") # load in data form excel file using pandas\n",
    "data300.head() # print the first few rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4d18c6-762e-4296-b070-603af76af5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data600 = pd.read_excel(\"cleaned_bioreactor_data.xlsx\", engine=\"openpyxl\", sheet_name=\"600\") # load in data form excel file using pandas\n",
    "data600.head() # print the first few rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14b1dfb-8e8e-426a-92fd-5244bfae6952",
   "metadata": {},
   "outputs": [],
   "source": [
    "data900 = pd.read_excel(\"cleaned_bioreactor_data.xlsx\", engine=\"openpyxl\", sheet_name=\"900\") # load in data form excel file using pandas\n",
    "data900.head() # print the first few rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788748b3-fb71-4e91-9782-3359998add73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1200 = pd.read_excel(\"cleaned_bioreactor_data.xlsx\", engine=\"openpyxl\", sheet_name=\"1200\") # load in data form excel file using pandas\n",
    "data1200.head() # print the first few rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7c2112-0c9e-42fc-9505-d2bd17f2e828",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check for non-numeric columns \n",
    "data1200.dtypes\n",
    "\n",
    "# result (float64) indicates that all data is numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db5cd24-c8e5-48a1-921b-bbdc357bf860",
   "metadata": {},
   "source": [
    "[Back to top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152ced8b-6207-4edc-83b8-0cda4e109355",
   "metadata": {},
   "source": [
    "---\n",
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f1e429-b84d-4cd2-99d3-62c9bda8a126",
   "metadata": {},
   "source": [
    "#### REGEM Imputation\n",
    "Missing data is a common problem due to operators being unable to take measurements or sensor failure. Several points are missing from these datasets. Regression-based imputation (REGEM) is used below to impute missing data points for each of the four datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c6a6a8-03a1-4af7-a735-50a137af08c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply REGEM, filling in missing values, using iterative imputer\n",
    "imputer=IterativeImputer(max_iter=10, random_state=42) # create an instance of the imputer \n",
    "data300_imputed=pd.DataFrame(imputer.fit_transform(data300),columns=data300.columns) # impute missing data points\n",
    "print(\"Data after REGEM imputation:\")\n",
    "data300_imputed.head() # print the first few rows of imputed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5febb88a-23c4-4daa-8435-f5abc0fddcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply REGEM, filling in missing values, using iterative imputer\n",
    "imputer=IterativeImputer(max_iter=10, random_state=42)\n",
    "data600_imputed=pd.DataFrame(imputer.fit_transform(data600),columns=data600.columns)\n",
    "print(\"Data after REGEM imputation:\")\n",
    "data600_imputed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0deb12d-77ce-4245-a86a-85ec828be50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply REGEM, filling in missing values, using iterative imputer\n",
    "imputer=IterativeImputer(max_iter=10, random_state=42)\n",
    "data900_imputed=pd.DataFrame(imputer.fit_transform(data900),columns=data900.columns)\n",
    "print(\"Data after REGEM imputation:\")\n",
    "data900_imputed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99ef0e3-f982-46bb-9f2a-02ee431e352b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply REGEM, filling in missing values, using iterative imputer\n",
    "imputer=IterativeImputer(max_iter=10, random_state=42)\n",
    "data1200_imputed=pd.DataFrame(imputer.fit_transform(data1200),columns=data1200.columns)\n",
    "print(\"Data after REGEM imputation:\")\n",
    "data1200_imputed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3f193d-6aa3-4c42-a48d-4f7af53d369d",
   "metadata": {},
   "source": [
    "#### Polynomial Fitting\n",
    "\n",
    "Polynomial fitting was applied as a data smoothing pre-treatment to reduce experimental fluctuations. \n",
    "\n",
    "Note: polynomial fitting is not an appropriate model to simulate the reaction environment. It provides an approximation for a specific experimental condition, and is not able to dynamically model the system. Thus, a more complex model (the ANN) is needed to simulate the environment for DRL training.\n",
    "\n",
    "Note: the paper states that 3rd-order polynomial fitting is applied. However, in the \"fitted data.xlsx\" file provided with the paper, the polynomial fitting was actually 2nd-order. In this code below, we apply 2nd-order polynomial fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341153f4-2268-47f6-88a1-d8b3e54b21c3",
   "metadata": {},
   "source": [
    "##### 300 mg/L Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d15dbf8-d1a2-4567-b0dd-5acc345eff21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#adding 3rd order polynomial regression to CPC, nitrate, and biomass to replicate plot in paper\n",
    "#using imputed data (above) and then generating smooth curves to plot\n",
    "\n",
    "# Biomass\n",
    "x300_bio = data300_imputed[[\"Time (Days)\"]] # adds input x to regression\n",
    "y300_bio = data300_imputed[\"Biomass (mg/mL)\"]  #y target number one, biomass\n",
    "poly300_bio = PolynomialFeatures(degree=2) #makes 2nd order polynomial \n",
    "x300_bio_poly = poly300_bio.fit_transform(x300_bio) #Actually creates the polynomial features from time values\n",
    "model300_bio = LinearRegression().fit(x300_bio_poly, y300_bio) #trains the regression model to learn a curve that fits your biomass data over time\n",
    "\n",
    "x300_vals=data300_imputed[\"Time (Days)\"] #grabs full age column again to have range for smoothed values\n",
    "x300_dense = np.linspace(x300_vals.min(), x300_vals.max(), 200).reshape(-1, 1) #makes 200 evenly spaced time points between first and last day and gives smooth line when predicting values between them\n",
    "\n",
    "x300_dense_bio = poly300_bio.transform(x300_dense) #Turns smooth x-values into polynomial features\n",
    "y300_dense_bio = model300_bio.predict(x300_dense_bio)#Uses the model to predict biomass values at all the smooth time points.\n",
    "\n",
    "# Nitrate\n",
    "nitrate_data300_imputed = data300_imputed.dropna(subset=[\"Nitrate (mg/mL)\"])\n",
    "x300_nit = nitrate_data300_imputed[[\"Time (Days)\"]]\n",
    "y300_nit = nitrate_data300_imputed[\"Nitrate (mg/mL)\"]\n",
    "poly300_nit = PolynomialFeatures(degree=2)\n",
    "x300_nit_poly = poly300_nit.fit_transform(x300_nit)\n",
    "model300_nit = LinearRegression().fit(x300_nit_poly, y300_nit)\n",
    "\n",
    "x300_dense_nit = poly300_nit.transform(x300_dense)\n",
    "y300_dense_nit = model300_nit.predict(x300_dense_nit)\n",
    "\n",
    "# C-PC smoothing\n",
    "cpc_data300_imputed = data300_imputed.dropna(subset=[\"C-PC (mg/mL)\"])\n",
    "x300_cpc = cpc_data300_imputed[[\"Time (Days)\"]]\n",
    "y300_cpc = cpc_data300_imputed[\"C-PC (mg/mL)\"]\n",
    "poly300_cpc = PolynomialFeatures(degree=2)\n",
    "x300_cpc_poly = poly300_cpc.fit_transform(x300_cpc)\n",
    "model300_cpc = LinearRegression().fit(x300_cpc_poly, y300_cpc)\n",
    "\n",
    "x300_dense_cpc = poly300_cpc.transform(x300_dense)\n",
    "y300_dense_cpc = model300_cpc.predict(x300_dense_cpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a943b59a-18f0-470a-bca3-02a544b49511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot polynomial fit over original data\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(6, 6))\n",
    "x_vals = data300[\"Time (Days)\"] #grabs raw age values from original data to plot raw data\n",
    "\n",
    "\n",
    "#plotting raw data for biomass and nitrate on left y-axis\n",
    "ax1.scatter(x_vals, data300[\"Biomass (mg/mL)\"], color='blue', label='Biomass (raw)',s=20)\n",
    "ax1.scatter(x_vals, data300[\"Nitrate (mg/mL)\"], color='red', label='Nitrate (raw)',s=20)\n",
    "\n",
    "#draws a smooth biomass curve using predicted values (y_dense_bio/y_dense_nitrate) over a smooth time range (x_dense) for nitrate and biomass\n",
    "ax1.plot(x300_dense, y300_dense_bio, color='blue', label='Biomass (fit)')\n",
    "ax1.plot(x300_dense, y300_dense_nit, color='red', label='Nitrate (fit)')\n",
    "\n",
    "#limits and labels for primary y-axis and x-axis (limits based on paper to make look the same)\n",
    "ax1.set_xlabel(\"Time (days)\")\n",
    "ax1.set_ylabel(\"Biomass, Nitrate (mg/L)\")\n",
    "ax1.set_xlim(0, 18)\n",
    "ax1.set_ylim(0, 1200)\n",
    "\n",
    "#adds CPC on right axis\n",
    "ax2 = ax1.twinx() #twin function creates secondary y-axis that shares same x-axis but has different units and limits than primary y-axis\n",
    "#plots raw CPC data\n",
    "ax2.scatter(data300[\"Time (Days)\"], data300[\"C-PC (mg/mL)\"], color='green', label='C-PC (raw)', s=20)\n",
    "#plots smoothed fitted line over raw data\n",
    "ax2.plot(x300_dense, y300_dense_cpc, color='green', label='C-PC (fit)')\n",
    "\n",
    "#labels secondary y-axis and adds scale\n",
    "ax2.set_ylabel(\"C-PC (mg/L)\")\n",
    "ax2.set_ylim(0, 25)\n",
    "\n",
    "#combines legends from both axes\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc=\"upper left\")\n",
    "\n",
    "#adds title\n",
    "plt.title(\"Biomass, Nitrate, and C-PC Over Time (Raw + Fit)\")\n",
    "#adds gridlines\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f955964f-7674-4901-9900-b09085124a1e",
   "metadata": {},
   "source": [
    "##### 600 mg/L Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc01c9d-b436-4eda-9c7d-de583b01a5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding 3rd order polynomial regression to CPC, nitrate, and biomass to replicate plot in paper\n",
    "#using imputed data (above) and then generating smooth curves to plot\n",
    "\n",
    "# Biomass\n",
    "x600_bio = data600_imputed[[\"Time (Days)\"]] # adds input x to regression\n",
    "y600_bio = data600_imputed[\"Biomass (mg/mL)\"]  #y target number one, biomass\n",
    "poly600_bio = PolynomialFeatures(degree=2) #makes 3rd order polynomial \n",
    "x600_bio_poly = poly600_bio.fit_transform(x600_bio) #Actually creates the polynomial features from time values\n",
    "model600_bio = LinearRegression().fit(x600_bio_poly, y600_bio) #trains the regression model to learn a curve that fits your biomass data over time\n",
    "\n",
    "x600_vals=data600_imputed[\"Time (Days)\"] #grabs full age column again to have range for smoothed values\n",
    "x600_dense = np.linspace(x600_vals.min(), x600_vals.max(), 200).reshape(-1, 1) #makes 200 evenly spaced time points between first and last day and gives smooth line when predicting values between them\n",
    "\n",
    "x600_dense_bio = poly600_bio.transform(x600_dense) #Turns smooth x-values into polynomial features\n",
    "y600_dense_bio = model600_bio.predict(x600_dense_bio)#Uses the model to predict biomass values at all the smooth time points.\n",
    "\n",
    "# Nitrate\n",
    "nitrate_data600_imputed = data600_imputed.dropna(subset=[\"Nitrate (mg/mL)\"])\n",
    "x600_nit = nitrate_data600_imputed[[\"Time (Days)\"]]\n",
    "y600_nit = nitrate_data600_imputed[\"Nitrate (mg/mL)\"]\n",
    "poly600_nit = PolynomialFeatures(degree=2)\n",
    "x600_nit_poly = poly600_nit.fit_transform(x600_nit)\n",
    "model600_nit = LinearRegression().fit(x600_nit_poly, y600_nit)\n",
    "\n",
    "x600_dense_nit = poly600_nit.transform(x600_dense)\n",
    "y600_dense_nit = model600_nit.predict(x600_dense_nit)\n",
    "\n",
    "# C-PC smoothing\n",
    "cpc_data600_imputed = data600_imputed.dropna(subset=[\"C-PC (mg/mL)\"])\n",
    "x600_cpc = cpc_data600_imputed[[\"Time (Days)\"]]\n",
    "y600_cpc = cpc_data600_imputed[\"C-PC (mg/mL)\"]\n",
    "poly600_cpc = PolynomialFeatures(degree=2)\n",
    "x600_cpc_poly = poly600_cpc.fit_transform(x600_cpc)\n",
    "model600_cpc = LinearRegression().fit(x600_cpc_poly, y600_cpc)\n",
    "\n",
    "x600_dense_cpc = poly600_cpc.transform(x600_dense)\n",
    "y600_dense_cpc = model600_cpc.predict(x600_dense_cpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49fd125-2c96-434f-9369-5669a5d5f531",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(6, 6))\n",
    "x_vals = data600[\"Time (Days)\"] #grabs raw age values from original data to plot raw data\n",
    "\n",
    "\n",
    "#plotting raw data for biomass and nitrate on left y-axis\n",
    "ax1.scatter(x_vals, data600[\"Biomass (mg/mL)\"], color='blue', label='Biomass (raw)',s=20)\n",
    "ax1.scatter(x_vals, data600[\"Nitrate (mg/mL)\"], color='red', label='Nitrate (raw)',s=20)\n",
    "\n",
    "#draws a smooth biomass curve using predicted values (y_dense_bio/y_dense_nitrate) over a smooth time range (x_dense) for nitrate and biomass\n",
    "ax1.plot(x600_dense, y600_dense_bio, color='blue', label='Biomass (fit)')\n",
    "ax1.plot(x600_dense, y600_dense_nit, color='red', label='Nitrate (fit)')\n",
    "\n",
    "#limits and labels for primary y-axis and x-axis (limits based on paper to make look the same)\n",
    "ax1.set_xlabel(\"Time (days)\")\n",
    "ax1.set_ylabel(\"Biomass, Nitrate (mg/L)\")\n",
    "ax1.set_xlim(0, 18)\n",
    "ax1.set_ylim(0, 1200)\n",
    "\n",
    "#adds CPC on right axis\n",
    "ax2 = ax1.twinx() #twin function creates secondary y-axis that shares same x-axis but has different units and limits than primary y-axis\n",
    "#plots raw CPC data\n",
    "ax2.scatter(data600[\"Time (Days)\"], data600[\"C-PC (mg/mL)\"], color='green', label='C-PC (raw)', s=20)\n",
    "#plots smoothed fitted line over raw data\n",
    "ax2.plot(x600_dense, y600_dense_cpc, color='green', label='C-PC (fit)')\n",
    "\n",
    "#labels secondary y-axis and adds scale\n",
    "ax2.set_ylabel(\"C-PC (mg/L)\")\n",
    "ax2.set_ylim(0, 35)\n",
    "\n",
    "#combines legends from both axes\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc=\"upper left\")\n",
    "\n",
    "#adds title\n",
    "plt.title(\"Biomass, Nitrate, and C-PC Over Time (Raw + Fit)\")\n",
    "#adds gridlines\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3c186f-7d58-4de1-bfb4-073998212a58",
   "metadata": {},
   "source": [
    "##### 900 mg/L Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f910c567-3786-4773-932d-956c7834eae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding 3rd order polynomial regression to CPC, nitrate, and biomass to replicate plot in paper\n",
    "#using imputed data (above) and then generating smooth curves to plot\n",
    "\n",
    "# Biomass\n",
    "x900_bio = data900_imputed[[\"Time (Days)\"]] # adds input x to regression\n",
    "y900_bio = data900_imputed[\"Biomass (mg/mL)\"]  #y target number one, biomass\n",
    "poly900_bio = PolynomialFeatures(degree=2) #makes 3rd order polynomial \n",
    "x900_bio_poly = poly900_bio.fit_transform(x900_bio) #Actually creates the polynomial features from time values\n",
    "model900_bio = LinearRegression().fit(x900_bio_poly, y900_bio) #trains the regression model to learn a curve that fits your biomass data over time\n",
    "\n",
    "x900_vals=data900_imputed[\"Time (Days)\"] #grabs full age column again to have range for smoothed values\n",
    "x900_dense = np.linspace(x900_vals.min(), x900_vals.max(), 200).reshape(-1, 1) #makes 200 evenly spaced time points between first and last day and gives smooth line when predicting values between them\n",
    "\n",
    "x900_dense_bio = poly900_bio.transform(x900_dense) #Turns smooth x-values into polynomial features\n",
    "y900_dense_bio = model900_bio.predict(x900_dense_bio)#Uses the model to predict biomass values at all the smooth time points.\n",
    "\n",
    "# Nitrate\n",
    "nitrate_data900_imputed = data900_imputed.dropna(subset=[\"Nitrate (mg/mL)\"])\n",
    "x900_nit = nitrate_data900_imputed[[\"Time (Days)\"]]\n",
    "y900_nit = nitrate_data900_imputed[\"Nitrate (mg/mL)\"]\n",
    "poly900_nit = PolynomialFeatures(degree=2)\n",
    "x900_nit_poly = poly900_nit.fit_transform(x900_nit)\n",
    "model900_nit = LinearRegression().fit(x900_nit_poly, y900_nit)\n",
    "\n",
    "x900_dense_nit = poly900_nit.transform(x900_dense)\n",
    "y900_dense_nit = model900_nit.predict(x900_dense_nit)\n",
    "\n",
    "# C-PC smoothing\n",
    "cpc_data900_imputed = data900_imputed.dropna(subset=[\"C-PC (mg/mL)\"])\n",
    "x900_cpc = cpc_data900_imputed[[\"Time (Days)\"]]\n",
    "y900_cpc = cpc_data900_imputed[\"C-PC (mg/mL)\"]\n",
    "poly900_cpc = PolynomialFeatures(degree=2)\n",
    "x900_cpc_poly = poly900_cpc.fit_transform(x900_cpc)\n",
    "model900_cpc = LinearRegression().fit(x900_cpc_poly, y900_cpc)\n",
    "\n",
    "x900_dense_cpc = poly900_cpc.transform(x900_dense)\n",
    "y900_dense_cpc = model900_cpc.predict(x900_dense_cpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aa95f4-3b2c-4c0e-b607-8e7ca8e4c8bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(6, 6))\n",
    "x_vals = data900[\"Time (Days)\"] #grabs raw age values from original data to plot raw data\n",
    "\n",
    "\n",
    "#plotting raw data for biomass and nitrate on left y-axis\n",
    "ax1.scatter(x_vals, data900[\"Biomass (mg/mL)\"], color='blue', label='Biomass (raw)',s=20)\n",
    "ax1.scatter(x_vals, data900[\"Nitrate (mg/mL)\"], color='red', label='Nitrate (raw)',s=20)\n",
    "\n",
    "#draws a smooth biomass curve using predicted values (y_dense_bio/y_dense_nitrate) over a smooth time range (x_dense) for nitrate and biomass\n",
    "ax1.plot(x900_dense, y900_dense_bio, color='blue', label='Biomass (fit)')\n",
    "ax1.plot(x900_dense, y900_dense_nit, color='red', label='Nitrate (fit)')\n",
    "\n",
    "#limits and labels for primary y-axis and x-axis (limits based on paper to make look the same)\n",
    "ax1.set_xlabel(\"Time (days)\")\n",
    "ax1.set_ylabel(\"Biomass, Nitrate (mg/L)\")\n",
    "ax1.set_xlim(0, 18)\n",
    "ax1.set_ylim(0, 1200)\n",
    "\n",
    "#adds CPC on right axis\n",
    "ax2 = ax1.twinx() #twin function creates secondary y-axis that shares same x-axis but has different units and limits than primary y-axis\n",
    "#plots raw CPC data\n",
    "ax2.scatter(data900[\"Time (Days)\"], data900[\"C-PC (mg/mL)\"], color='green', label='C-PC (raw)', s=20)\n",
    "#plots smoothed fitted line over raw data\n",
    "ax2.plot(x900_dense, y900_dense_cpc, color='green', label='C-PC (fit)')\n",
    "\n",
    "#labels secondary y-axis and adds scale\n",
    "ax2.set_ylabel(\"C-PC (mg/L)\")\n",
    "ax2.set_ylim(0, 45)\n",
    "\n",
    "#combines legends from both axes\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc=\"upper left\")\n",
    "\n",
    "#adds title\n",
    "plt.title(\"Biomass, Nitrate, and C-PC Over Time (Raw + Fit)\")\n",
    "#adds gridlines\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fffc686-db67-41e8-b677-232a0aea11e0",
   "metadata": {},
   "source": [
    "##### 1200 mg/L Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712434d7-99c5-4de2-ba5e-1e89e19f6fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding 3rd order polynomial regression to CPC, nitrate, and biomass to replicate plot in paper\n",
    "#using imputed data (above) and then generating smooth curves to plot\n",
    "\n",
    "# Biomass\n",
    "x1200_bio = data1200_imputed[[\"Time (Days)\"]] # adds input x to regression\n",
    "y1200_bio = data1200_imputed[\"Biomass (mg/mL)\"]  #y target number one, biomass\n",
    "poly1200_bio = PolynomialFeatures(degree=2) #makes 3rd order polynomial \n",
    "x1200_bio_poly = poly1200_bio.fit_transform(x1200_bio) #Actually creates the polynomial features from time values\n",
    "model1200_bio = LinearRegression().fit(x1200_bio_poly, y1200_bio) #trains the regression model to learn a curve that fits your biomass data over time\n",
    "\n",
    "x1200_vals=data1200_imputed[\"Time (Days)\"] #grabs full age column again to have range for smoothed values\n",
    "x1200_dense = np.linspace(x1200_vals.min(), x1200_vals.max(), 200).reshape(-1, 1) #makes 200 evenly spaced time points between first and last day and gives smooth line when predicting values between them\n",
    "\n",
    "x1200_dense_bio = poly1200_bio.transform(x1200_dense) #Turns smooth x-values into polynomial features\n",
    "y1200_dense_bio = model1200_bio.predict(x1200_dense_bio)#Uses the model to predict biomass values at all the smooth time points.\n",
    "\n",
    "# Nitrate\n",
    "nitrate_data1200_imputed = data1200_imputed.dropna(subset=[\"Nitrate (mg/mL)\"])\n",
    "x1200_nit = nitrate_data1200_imputed[[\"Time (Days)\"]]\n",
    "y1200_nit = nitrate_data1200_imputed[\"Nitrate (mg/mL)\"]\n",
    "poly1200_nit = PolynomialFeatures(degree=2)\n",
    "x1200_nit_poly = poly1200_nit.fit_transform(x1200_nit)\n",
    "model1200_nit = LinearRegression().fit(x1200_nit_poly, y1200_nit)\n",
    "\n",
    "x1200_dense_nit = poly1200_nit.transform(x1200_dense)\n",
    "y1200_dense_nit = model1200_nit.predict(x1200_dense_nit)\n",
    "\n",
    "# C-PC smoothing\n",
    "cpc_data1200_imputed = data1200_imputed.dropna(subset=[\"C-PC (mg/mL)\"])\n",
    "x1200_cpc = cpc_data1200_imputed[[\"Time (Days)\"]]\n",
    "y1200_cpc = cpc_data1200_imputed[\"C-PC (mg/mL)\"]\n",
    "poly1200_cpc = PolynomialFeatures(degree=2)\n",
    "x1200_cpc_poly = poly1200_cpc.fit_transform(x1200_cpc)\n",
    "model1200_cpc = LinearRegression().fit(x1200_cpc_poly, y1200_cpc)\n",
    "\n",
    "x1200_dense_cpc = poly1200_cpc.transform(x1200_dense)\n",
    "y1200_dense_cpc = model1200_cpc.predict(x1200_dense_cpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c27e601-6523-4605-94aa-9d7a0a501d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(6, 6))\n",
    "x_vals = data1200[\"Time (Days)\"] #grabs raw age values from original data to plot raw data\n",
    "\n",
    "\n",
    "#plotting raw data for biomass and nitrate on left y-axis\n",
    "ax1.scatter(x_vals, data1200[\"Biomass (mg/mL)\"], color='blue', label='Biomass (raw)',s=20)\n",
    "ax1.scatter(x_vals, data1200[\"Nitrate (mg/mL)\"], color='red', label='Nitrate (raw)',s=20)\n",
    "\n",
    "#draws a smooth biomass curve using predicted values (y_dense_bio/y_dense_nitrate) over a smooth time range (x_dense) for nitrate and biomass\n",
    "ax1.plot(x1200_dense, y1200_dense_bio, color='blue', label='Biomass (fit)')\n",
    "ax1.plot(x1200_dense, y1200_dense_nit, color='red', label='Nitrate (fit)')\n",
    "\n",
    "#limits and labels for primary y-axis and x-axis (limits based on paper to make look the same)\n",
    "ax1.set_xlabel(\"Time (days)\")\n",
    "ax1.set_ylabel(\"Biomass, Nitrate (mg/L)\")\n",
    "ax1.set_xlim(0, 60)\n",
    "ax1.set_ylim(0, 4000)\n",
    "\n",
    "#adds CPC on right axis\n",
    "ax2 = ax1.twinx() #twin function creates secondary y-axis that shares same x-axis but has different units and limits than primary y-axis\n",
    "#plots raw CPC data\n",
    "ax2.scatter(data1200[\"Time (Days)\"], data1200[\"C-PC (mg/mL)\"], color='green', label='C-PC (raw)', s=20)\n",
    "#plots smoothed fitted line over raw data\n",
    "ax2.plot(x1200_dense, y1200_dense_cpc, color='green', label='C-PC (fit)')\n",
    "\n",
    "#labels secondary y-axis and adds scale\n",
    "ax2.set_ylabel(\"C-PC (mg/L)\")\n",
    "ax2.set_ylim(0, 1500)\n",
    "\n",
    "#combines legends from both axes\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc=\"upper left\")\n",
    "\n",
    "#adds title\n",
    "plt.title(\"Biomass, Nitrate, and C-PC Over Time (Raw + Fit)\")\n",
    "#adds gridlines\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d95cb5-b99d-4de3-a818-affb56d621a3",
   "metadata": {},
   "source": [
    "##### Format Polynomial Predicted Values into DataFrame for each Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15266943-d8a6-4e79-a36f-1e4af7444721",
   "metadata": {},
   "outputs": [],
   "source": [
    "time300 = np.arange(18) # create time array with values 0-17, as done in original paper\n",
    "time300_features = poly300_bio.fit_transform(time300.reshape(-1,1)) #Actually creates the polynomial features from time values, which are the same for each model\n",
    "\n",
    "biomass300_pred = model300_bio.predict(time300_features) #predicted biomass values for time steps\n",
    "nit300_pred = model300_nit.predict(time300_features) #predicted nitrogen values for time steps\n",
    "cpc300_pred = model300_cpc.predict(time300_features) #predicted cpc values for time steps\n",
    "\n",
    "# Store times and predicted biomass, nitrate, and C-PC in one dataframe\n",
    "fitted300_df = pd.DataFrame({'Time (Days)': time300, \n",
    "                             'Biomass (mg/mL)': biomass300_pred, \n",
    "                             'Nitrate (mg/mL)': nit300_pred, \n",
    "                             'C-PC (mg/mL)':cpc300_pred})\n",
    "fitted300_df.head() # print the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a348002-08dc-43a8-b407-cacef8874d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "time600 = np.arange(18) # create time array with values 0-17, as done in original paper\n",
    "time600_features = poly600_bio.fit_transform(time600.reshape(-1,1)) #Actually creates the polynomial features from time values, which are the same for each model\n",
    "\n",
    "biomass600_pred = model600_bio.predict(time600_features) #predicted biomass values for time steps\n",
    "nit600_pred = model600_nit.predict(time600_features) #predicted nitrogen values for time steps\n",
    "cpc600_pred = model600_cpc.predict(time600_features) #predicted cpc values for time steps\n",
    "\n",
    "# Store times and predicted biomass, nitrate, and C-PC in one dataframe\n",
    "fitted600_df = pd.DataFrame({'Time (Days)': time600, \n",
    "                             'Biomass (mg/mL)': biomass600_pred, \n",
    "                             'Nitrate (mg/mL)': nit600_pred, \n",
    "                             'C-PC (mg/mL)':cpc600_pred})\n",
    "fitted600_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d103466-1ff0-4d7c-9828-7dd8354c4a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "time900 = np.arange(18) # create time array with values 0-17, as done in original paper\n",
    "time900_features = poly900_bio.fit_transform(time900.reshape(-1,1)) #Actually creates the polynomial features from time values, which are the same for each model\n",
    "\n",
    "biomass900_pred = model900_bio.predict(time900_features) #predicted biomass values for time steps\n",
    "nit900_pred = model900_nit.predict(time900_features) #predicted nitrogen values for time steps\n",
    "cpc900_pred = model900_cpc.predict(time900_features) #predicted cpc values for time steps\n",
    "\n",
    "# Store times and predicted biomass, nitrate, and C-PC in one dataframe\n",
    "fitted900_df = pd.DataFrame({'Time (Days)': time900, \n",
    "                             'Biomass (mg/mL)': biomass900_pred, \n",
    "                             'Nitrate (mg/mL)': nit900_pred, \n",
    "                             'C-PC (mg/mL)':cpc900_pred})\n",
    "fitted900_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61f6a4c-61fd-4452-8b09-8b51cd3dd71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time1200 = np.arange(56) # create time array with values 0-55, as done in original paper\n",
    "time1200_features = poly1200_bio.fit_transform(time1200.reshape(-1,1)) #Actually creates the polynomial features from time values, which are the same for each model\n",
    "\n",
    "biomass1200_pred = model1200_bio.predict(time1200_features) #predicted biomass values for time steps\n",
    "nit1200_pred = model1200_nit.predict(time1200_features) #predicted nitrogen values for time steps\n",
    "cpc1200_pred = model1200_cpc.predict(time1200_features) #predicted cpc values for time steps\n",
    "\n",
    "# Store times and predicted biomass, nitrate, and C-PC in one dataframe\n",
    "fitted1200_df = pd.DataFrame({'Time (Days)': time1200, \n",
    "                             'Biomass (mg/mL)': biomass1200_pred, \n",
    "                             'Nitrate (mg/mL)': nit1200_pred, \n",
    "                             'C-PC (mg/mL)':cpc1200_pred})\n",
    "fitted1200_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643039cd-487a-44e1-9614-6388d1c728f8",
   "metadata": {},
   "source": [
    "---\n",
    "## ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d79fa71-30a0-476e-a488-d7a6edb44814",
   "metadata": {},
   "source": [
    "#### Format Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc34a1a-f956-4bab-8f67-4763bc9ba6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to define output data as the delta between the current and next time step\n",
    "def create_training_data(df):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(len(df) - 1):\n",
    "        t, x, N, C_PC = df.iloc[i][['Time (Days)', 'Biomass (mg/mL)', 'Nitrate (mg/mL)', 'C-PC (mg/mL)']]\n",
    "        t_next, x_next, N_next, C_PC_next = df.iloc[i+1][['Time (Days)', 'Biomass (mg/mL)', 'Nitrate (mg/mL)', 'C-PC (mg/mL)']]\n",
    "\n",
    "        input_vec = [t, x, N, C_PC]\n",
    "        output_vec = [t_next - t, x_next - x, N_next - N, C_PC_next - C_PC]\n",
    "\n",
    "        X.append(input_vec)\n",
    "        Y.append(output_vec)\n",
    "\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "# Load and process all 3 experiments\n",
    "X_all, Y_all = [], []\n",
    "for df in [fitted300_df, fitted900_df, fitted1200_df]:\n",
    "    X, Y = create_training_data(df)\n",
    "    X_all.append(X)\n",
    "    Y_all.append(Y)\n",
    "\n",
    "# Stack all together\n",
    "X_train = np.vstack(X_all)\n",
    "Y_train = np.vstack(Y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3008a87d-59a6-4552-8031-bf08f11e8df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation set from 600 mg/L data set\n",
    "\n",
    "X_validation, Y_validation = create_training_data(fitted600_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d477c233-e6e1-4b7d-849b-4566325795d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data to a mean of zero and a mean of 0 and standard deviation of 1\n",
    "\n",
    "# create instances of scalers\n",
    "scaler_X = StandardScaler()\n",
    "scaler_Y = StandardScaler()\n",
    "\n",
    "# fit to training data and scale training data\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "Y_train_scaled = scaler_Y.fit_transform(Y_train)\n",
    "\n",
    "# scale validation data\n",
    "X_validation_scaled = scaler_X.transform(X_validation)\n",
    "Y_validation_scaled = scaler_Y.transform(Y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391004f1-474a-46b8-a910-271ae961e225",
   "metadata": {},
   "source": [
    "#### Importing packages and building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef8d303-96a8-4e4f-8cab-f3aad9993d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65f5d12-50c2-4975-910f-bf981e3fb532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified version with 600 mg/L experiment used as validation set, other three experiments used as training data\n",
    "    # (as opposed to using a 15% validation split from the three training experiments)\n",
    "\n",
    "# === Define the model ===\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(4,)),   # Input layer (4) → Hidden 1\n",
    "    Dense(64, activation='relu'),                      # Hidden 2\n",
    "    Dropout(0.15),                                     # Dropout (keep_prob=0.85)\n",
    "    Dense(4)                                           # Output layer (Δt, Δx, ΔN, ΔC-PC)\n",
    "])\n",
    "\n",
    "# === Compile model ===\n",
    "model.compile(optimizer=Adam(), loss='mse')\n",
    "\n",
    "# === Train the model ===\n",
    "history = model.fit(X_train_scaled, Y_train_scaled,\n",
    "                    epochs=10000,               # Feel free to reduce to ~1000 to test first\n",
    "                    batch_size=16,\n",
    "                    validation_data=(X_validation_scaled, Y_validation_scaled),      # or use an explicit X_val/Y_val if you prefer\n",
    "                    verbose=1)                  # Set to 1 if you want to watch training live\n",
    "\n",
    "# === Plot training + validation loss ===\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('ANN Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(\"Loss_v_Epoch.png\")\n",
    "\n",
    "# === Save model ===\n",
    "model.save('plectonema_ann_model.h5')\n",
    "print(\"Model saved as 'plectonema_ann_model.h5'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac623305-9497-41bc-b257-721e5adae14e",
   "metadata": {},
   "source": [
    "#### Load in Model from Saved Parameters and Fit Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1ac520-d509-47b9-b10f-ed0d07b55edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Define the model ===\n",
    "ann_model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(4,)),   # Input layer (4) → Hidden 1\n",
    "    Dense(64, activation='relu'),                      # Hidden 2\n",
    "    Dropout(0.15),                                     # Dropout (keep_prob=0.85)\n",
    "    Dense(4)                                           # Output layer (Δt, Δx, ΔN, ΔC-PC)\n",
    "])\n",
    "\n",
    "# === Compile model ===\n",
    "ann_model.compile(optimizer=Adam(), loss=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "# === Load in weights from saved file ====\n",
    "ann_model.load_weights(\"plectonema_ann_model_Attempt3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f1f353-b10b-4c1b-85ba-fa3aa3388e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define initial state as first row of data from validation set\n",
    "current_state = scaler_X.transform(np.array([1, data600.loc[0,\"Biomass (mg/mL)\"], data600.loc[0,\"Nitrate (mg/mL)\"], data600.loc[0,\"C-PC (mg/mL)\"]]).reshape(1, -1))\n",
    "\n",
    "t_range = range(1, 18) # time range to run through days 1-17\n",
    "trajectory = [current_state.copy()] # create a list to store each state for future plotting\n",
    "\n",
    "for t in t_range:\n",
    "    \n",
    "    # Predict the delta in scaled space\n",
    "    delta_scaled = ann_model.predict(current_state, verbose=0)\n",
    "    \n",
    "    # Unscale both delta and current state\n",
    "    delta_unscaled = scaler_Y.inverse_transform(delta_scaled)[0]\n",
    "    current_state_unscaled = scaler_X.inverse_transform(current_state)[0]\n",
    "    \n",
    "    # Add delta to unscaled state\n",
    "    next_state_unscaled = current_state_unscaled + delta_unscaled\n",
    "    \n",
    "    # Re-scale the new state for the next prediction\n",
    "    current_state = scaler_X.transform(next_state_unscaled.reshape(1, -1))\n",
    "\n",
    "    # Save the new state\n",
    "    trajectory.append(current_state.copy())\n",
    "\n",
    "# Convert trajectory to NumPy array for easier handling\n",
    "trajectory = np.array(trajectory)\n",
    "trajectory_unscaled = scaler_X.inverse_transform(trajectory.reshape(-1, trajectory.shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de18fcff-5779-4c6b-a13d-fdcbb9c42c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ANN prediction\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(6, 6))\n",
    "x_vals = data600[\"Time (Days)\"] #grabs raw age values from original data to plot raw data\n",
    "\n",
    "ax1.scatter(x_vals, data600[\"Biomass (mg/mL)\"], color='blue', label='Biomass (raw)',s=20)\n",
    "ax1.scatter(x_vals, data600[\"Nitrate (mg/mL)\"], color='red', label='Nitrate (raw)',s=20)\n",
    "ax1.scatter(x_vals, data600[\"C-PC (mg/mL)\"], color='green', label='C-PC (raw)',s=20)\n",
    "\n",
    "plt.plot(trajectory_unscaled[:,0], trajectory_unscaled[:,1],  color='blue', label='Biomass (predicted)')\n",
    "plt.plot(trajectory_unscaled[:,0], trajectory_unscaled[:,2],  color='red', label='Nitrate (predicted)')\n",
    "plt.plot(trajectory_unscaled[:,0], trajectory_unscaled[:,3],  color='green', label='C-PC (predicted)')\n",
    "\n",
    "#limits and labels for primary y-axis and x-axis (limits based on paper to make look the same)\n",
    "ax1.set_xlabel(\"Time (days)\")\n",
    "ax1.set_ylabel(\"Concentration (mg/L)\")\n",
    "ax1.set_xlim(0, 18)\n",
    "ax1.set_ylim(0, 1100)\n",
    "plt.legend()\n",
    "\n",
    "#adds title\n",
    "plt.title(\"ANN Prediction for Validation Set\")\n",
    "#adds gridlines\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a308926-eb68-4244-9d14-7f9600927bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "UPDATE_FREQ = 20  # print average reward every 20 episodes\n",
    "\n",
    "\n",
    "# === Environment ===\n",
    "class BioreactorEnv:\n",
    "    def __init__(self, ann_model, scaler_X, scaler_Y, data600, max_nitrate=2000):\n",
    "        self.ann_model = ann_model\n",
    "        self.scaler_X = scaler_X\n",
    "        self.scaler_Y = scaler_Y\n",
    "        self.data600 = data600\n",
    "        self.max_steps = 17\n",
    "        self.max_nitrate = max_nitrate\n",
    "        self.dose_values = [0, 50, 100, 150, 200, 250]\n",
    "        self.reset()\n",
    "\n",
    "    def _get_initial_state(self):\n",
    "        return np.array([\n",
    "            1,\n",
    "            self.data600.loc[0, \"Biomass (mg/mL)\"],\n",
    "            self.data600.loc[0, \"Nitrate (mg/mL)\"],\n",
    "            self.data600.loc[0, \"C-PC (mg/mL)\"]\n",
    "        ])\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.total_nitrate_added = 0\n",
    "        self.unscaled_state = self._get_initial_state()\n",
    "        self.scaled_state = self.scaler_X.transform([self.unscaled_state])[0]\n",
    "        return self.scaled_state\n",
    "\n",
    "    def step(self, action):\n",
    "        n_add = self.dose_values[action]\n",
    "        if self.total_nitrate_added + n_add > self.max_nitrate:\n",
    "            n_add = 0\n",
    "        self.total_nitrate_added += n_add\n",
    "\n",
    "        self.unscaled_state[2] += n_add\n",
    "        input_scaled = self.scaler_X.transform([self.unscaled_state])[0]\n",
    "\n",
    "        delta_scaled = self.ann_model.predict(np.array([input_scaled]), verbose=0)\n",
    "        delta_unscaled = self.scaler_Y.inverse_transform(delta_scaled)[0]\n",
    "\n",
    "        next_unscaled = self.unscaled_state + delta_unscaled\n",
    "\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= self.max_steps\n",
    "\n",
    "        if done:\n",
    "            biomass = max(next_unscaled[1], 1e-6)\n",
    "            reward = next_unscaled[3] / biomass\n",
    "        else:\n",
    "            reward = -0.1\n",
    "\n",
    "        self.unscaled_state = next_unscaled\n",
    "        self.scaled_state = self.scaler_X.transform([self.unscaled_state])[0]\n",
    "        return self.scaled_state, reward, done, {}\n",
    "\n",
    "\n",
    "\n",
    "# === Actor-Critic Model ===\n",
    "class ActorCriticModel(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense1 = Dense(200, activation='relu')\n",
    "        self.logits = Dense(6)  # 6 nitrate dose levels\n",
    "        self.dense2 = Dense(200, activation='relu')\n",
    "        self.value = Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        return self.logits(x), self.value(self.dense2(x))\n",
    "\n",
    "class A3CAgent(threading.Thread):\n",
    "    def __init__(self, global_model, optimizer, ann_model, scaler_X, scaler_Y, data600):\n",
    "        super().__init__()\n",
    "        self.global_model = global_model\n",
    "        self.optimizer = optimizer\n",
    "        self.local_model = ActorCriticModel()\n",
    "        self.local_model(tf.convert_to_tensor(np.zeros((1, 4)), dtype=tf.float32))\n",
    "        self.local_model.set_weights(global_model.get_weights())\n",
    "        self.env = BioreactorEnv(ann_model, scaler_X, scaler_Y, data600)\n",
    "\n",
    "    def run(self):\n",
    "        global global_episode, global_rewards, global_step, reward_steps, lock\n",
    "\n",
    "        while True:\n",
    "            with lock:\n",
    "                if global_episode >= MAX_EPISODES:\n",
    "                    break\n",
    "                episode_num = global_episode\n",
    "                global_episode += 1\n",
    "\n",
    "            state = self.env.reset()\n",
    "            done = False\n",
    "            episode_reward = 0\n",
    "\n",
    "            while not done:\n",
    "                state_tensor = tf.convert_to_tensor(np.expand_dims(state, 0), dtype=tf.float32)\n",
    "                logits, _ = self.local_model(state_tensor)\n",
    "                action = tf.random.categorical(logits, 1)[0, 0].numpy()\n",
    "\n",
    "                next_state, reward, done, _ = self.env.step(action)\n",
    "                episode_reward += reward\n",
    "                state = next_state\n",
    "\n",
    "                with lock:\n",
    "                    global_step += 1\n",
    "                    global_rewards.append(reward)\n",
    "                    if len(global_rewards) >= 20:\n",
    "                        avg = np.mean(global_rewards[-20:])\n",
    "                        reward_steps.append(avg)\n",
    "\n",
    "            with lock:\n",
    "                if episode_num % UPDATE_FREQ == 0:\n",
    "                    print(f\"[Episode {episode_num}] Avg Reward (last 20 steps): {np.mean(global_rewards[-20:]):.4f}\")\n",
    "\n",
    "# === Training Entry Point ===\n",
    "def train_a3c(ann_model, scaler_X, scaler_Y, data600, episodes=2000, agents=4):\n",
    "    global global_episode, global_rewards, global_step, reward_steps, MAX_EPISODES, lock\n",
    "    global_episode = 0\n",
    "    global_rewards = []\n",
    "    reward_steps = []\n",
    "    global_step = 0\n",
    "    MAX_EPISODES = episodes\n",
    "    lock = threading.Lock()\n",
    "\n",
    "    global_model = ActorCriticModel()\n",
    "    global_model(tf.convert_to_tensor(np.zeros((1, 4)), dtype=tf.float32))\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    agent_threads = [\n",
    "        A3CAgent(global_model, optimizer, ann_model, scaler_X, scaler_Y, data600)\n",
    "        for _ in range(agents)\n",
    "    ]\n",
    "\n",
    "    for agent in agent_threads:\n",
    "        agent.start()\n",
    "    for agent in agent_threads:\n",
    "        agent.join()\n",
    "\n",
    "    # Plotting step-based learning curve\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(reward_steps)\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Moving Avg Reward (20 steps)\")\n",
    "    plt.title(\"A3C Learning Curve (C-PC / Biomass)\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return global_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5725b858-fb51-44c2-bdb7-2718731b1b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = train_a3c(ann_model, scaler_X, scaler_Y, data600, episodes=2000, agents=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6c876f-99a0-4583-94b1-ec95a16c54c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def simulate_agent(trained_model, ann_model, scaler_X, scaler_Y, data600):\n",
    "    env = BioreactorEnv(ann_model, scaler_X, scaler_Y, data600)\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "\n",
    "    nitrate_doses = []\n",
    "    cpc_vals = []\n",
    "    biomass_vals = []\n",
    "    days = []\n",
    "\n",
    "    while not done:\n",
    "        state_tensor = tf.convert_to_tensor(np.expand_dims(state, 0), dtype=tf.float32)\n",
    "        logits, _ = trained_model(state_tensor)\n",
    "        action = tf.random.categorical(logits, 1)[0, 0].numpy()\n",
    "\n",
    "        # Get nitrate value for the action\n",
    "        dose = env.dose_values[action]\n",
    "        nitrate_doses.append(dose)\n",
    "\n",
    "        # Save current C-PC and biomass from unscaled state\n",
    "        unscaled = scaler_X.inverse_transform([state])[0]\n",
    "        days.append(unscaled[0])\n",
    "        biomass_vals.append(unscaled[1])\n",
    "        cpc_vals.append(unscaled[3])\n",
    "\n",
    "        # Take step\n",
    "        state, reward, done, _ = env.step(action)\n",
    "\n",
    "    # Plot nitrate addition strategy\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(days, nitrate_doses, marker='o')\n",
    "    plt.xlabel(\"Day\")\n",
    "    plt.ylabel(\"Nitrate Added (mg/L)\")\n",
    "    plt.title(\"Agent’s Nitrate Dosing Strategy Over Time\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Optional: return for more plots\n",
    "    return days, nitrate_doses, biomass_vals, cpc_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd20603-245e-417b-a514-3455fe0cd005",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate_agent(trained_model, ann_model, scaler_X, scaler_Y, data600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aeab41-5f8f-4cd6-a675-92cbe93daa34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76025f59-c677-4e62-b9e9-7c017b2a1c97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bbac29-816c-437b-9b16-0c32d3e90999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad1c938-01c0-4833-b647-52115d5157fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7970465d-be55-478a-82e9-0a1da1f0485b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (default)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
